# -*- coding: utf-8 -*-
"""Real-ESRGAN Transfer learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jbJ845fxNxRicPXoIVbI2y8_PwsrqWjW
"""

!pip install torch torchvision
!pip install numpy opencv-python tqdm
!pip install tensorboardX

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision.transforms import transforms, ToTensor, ToPILImage
from torchvision.utils import save_image
from PIL import Image
import os
from tqdm import tqdm
from tensorboardX import SummaryWriter
import matplotlib.pyplot as plt

class ResidualBlock(nn.Module):
    def __init__(self):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)
        self.bn1 = nn.BatchNorm2d(64)
        self.prelu = nn.PReLU()
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)
        self.bn2 = nn.BatchNorm2d(64)

    def forward(self, x):
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.prelu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        out += x
        return out

class Generator(nn.Module):
    def __init__(self, in_channels=3, out_channels=3, n_residual_blocks=16):
        super(Generator, self).__init__()

        # Initial convolution block
        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=9, stride=1, padding=4)
        self.prelu = nn.PReLU()

        # Residual blocks
        res_blocks = []
        for _ in range(n_residual_blocks):
            res_blocks.append(ResidualBlock())
        self.res_blocks = nn.Sequential(*res_blocks)

        # Second conv block after residual blocks
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)
        self.bn2 = nn.BatchNorm2d(64)

        # Final output layer
        self.conv3 = nn.Conv2d(64, out_channels, kernel_size=9, stride=1, padding=4)

    def forward(self, x):
        out1 = self.prelu(self.conv1(x))
        out = self.res_blocks(out1)
        out = self.bn2(self.conv2(out))
        out = out1 + out
        out = self.conv3(out)
        return out

class Discriminator(nn.Module):
    def __init__(self, in_channels=3):
        super(Discriminator, self).__init__()

        def discriminator_block(in_filters, out_filters, stride=1, normalize=True):
            layers = [nn.Conv2d(in_filters, out_filters, kernel_size=3, stride=stride, padding=1)]
            if normalize:
                layers.append(nn.BatchNorm2d(out_filters))
            layers.append(nn.LeakyReLU(0.2, inplace=True))
            return layers

        self.model = nn.Sequential(
            *discriminator_block(in_channels, 64, normalize=False),
            *discriminator_block(64, 64, stride=2),
            *discriminator_block(64, 128),
            *discriminator_block(128, 128, stride=2),
            *discriminator_block(128, 256),
            *discriminator_block(256, 256, stride=2),
            *discriminator_block(256, 512),
            *discriminator_block(512, 512, stride=2),
            nn.Conv2d(512, 1, kernel_size=3, stride=1, padding=1)
        )

    def forward(self, img):
        return self.model(img)

class ImageDataset(Dataset):
    def __init__(self, lr_dir, hr_dir, transform=None):
        self.lr_dir = lr_dir
        self.hr_dir = hr_dir
        self.lr_images = sorted(os.listdir(lr_dir))
        self.hr_images = sorted(os.listdir(hr_dir))
        self.transform = transform

    def __len__(self):
        return len(self.lr_images)

    def __getitem__(self, index):
        lr_image = Image.open(os.path.join(self.lr_dir, self.lr_images[index])).convert('RGB')
        hr_image = Image.open(os.path.join(self.hr_dir, self.hr_images[index])).convert('RGB')

        if self.transform:
            lr_image = self.transform(lr_image)
            hr_image = self.transform(hr_image)

        return lr_image, hr_image

# Load and preprocess the dataset
lr_dir = '/content/drive/MyDrive/AI/Term 3/dataset/train/low_res'
hr_dir = '/content/drive/MyDrive/AI/Term 3/dataset/train/high_res'
batch_size = 16
transform = transforms.Compose([transforms.ToTensor()])

train_dataset = ImageDataset(lr_dir, hr_dir, transform=transform)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Initialize models
generator = Generator().to(device)
discriminator = Discriminator().to(device)

# Load pre-trained weights for transfer learning
pretrained_weight_path = '/content/drive/MyDrive/AI/Term 3/RealESRGAN_weights/RealESRGAN_x2.pth'
generator.load_state_dict(torch.load(pretrained_weight_path, map_location=device), strict=False)

# Define loss functions
criterion_GAN = nn.BCEWithLogitsLoss().to(device)
criterion_content = nn.L1Loss().to(device)

# Define optimizers
optimizer_G = optim.Adam(generator.parameters(), lr=1e-4)
optimizer_D = optim.Adam(discriminator.parameters(), lr=1e-4)

# Training loop
num_epochs = 100
log_dir = 'logs'
writer = SummaryWriter(log_dir)

'''''
# Transfer Learning
pretrained_weights_path = {
    'x2': '/content/drive/MyDrive/AI/Term 3/RealESRGAN_weights/RealESRGAN_x2.pth',
    'x4': '/content/drive/MyDrive/AI/Term 3/RealESRGAN_weights/RealESRGAN_x4.pth',
    'x8': '/content/drive/MyDrive/AI/Term 3/RealESRGAN_weights/RealESRGAN_x8.pth'
}
'''

# Load pre-trained weights for transfer learning
pretrained_weight_path = '/content/drive/MyDrive/AI/Term 3/RealESRGAN_weights/RealESRGAN_x2.pth'
generator.load_state_dict(torch.load(pretrained_weight_path, map_location=device), strict=False)

# Define loss functions
criterion_GAN = nn.BCEWithLogitsLoss().to(device)
criterion_content = nn.L1Loss().to(device)

# Define optimizers
optimizer_G = optim.Adam(generator.parameters(), lr=1e-4)
optimizer_D = optim.Adam(discriminator.parameters(), lr=1e-4)

# Training loop
num_epochs = 100
log_dir = 'logs'
writer = SummaryWriter(log_dir)

# GradScaler for mixed precision training
scaler = GradScaler()

for epoch in range(num_epochs):
    generator.train()
    discriminator.train()
    for i, (lr, hr) in enumerate(tqdm(train_dataloader)):
        lr = lr.to(device, non_blocking=True)
        hr = hr.to(device, non_blocking=True)

        # Train Discriminator
        optimizer_D.zero_grad()
        with autocast():
            fake_hr = generator(lr)
            real_out = discriminator(hr)
            fake_out = discriminator(fake_hr.detach())
            real_loss = criterion_GAN(real_out - torch.mean(fake_out), torch.ones_like(real_out))
            fake_loss = criterion_GAN(fake_out - torch.mean(real_out), torch.zeros_like(fake_out))
            d_loss = (real_loss + fake_loss) / 2

        scaler.scale(d_loss).backward(retain_graph=True)
        scaler.step(optimizer_D)
        scaler.update()

        # Train Generator
        optimizer_G.zero_grad()
        with autocast():
            fake_out = discriminator(fake_hr)
            g_loss_GAN = criterion_GAN(fake_out - torch.mean(real_out.detach()), torch.ones_like(fake_out))
            g_loss_content = criterion_content(fake_hr, hr)
            g_loss = g_loss_GAN + 1e-2 * g_loss_content

        scaler.scale(g_loss).backward()
        scaler.step(optimizer_G)
        scaler.update()

        # Logging
        writer.add_scalar('Loss/Discriminator', d_loss.item(), epoch * len(train_dataloader) + i)
        writer.add_scalar('Loss/Generator', g_loss.item(), epoch * len(train_dataloader) + i)

    print(f"Epoch [{epoch + 1}/{num_epochs}] Discriminator Loss: {d_loss.item():.4f}, Generator Loss: {g_loss.item():.4f}")

    # Save the current epoch's models
    torch.save(generator.state_dict(), f'/content/drive/MyDrive/AI/Term 3/dataset/generator_epoch_{epoch+1}.pth')
    torch.save(discriminator.state_dict(), f'/content/drive/MyDrive/AI/Term 3/dataset/discriminator_epoch_{epoch+1}.pth')

writer.close()

# Save the final models
torch.save(generator.state_dict(), '/content/drive/MyDrive/AI/Term 3/dataset/generator_final.pth')
torch.save(discriminator.state_dict(), '/content/drive/MyDrive/AI/Term 3/dataset/discriminator_final.pth')

import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt


# Load the trained generator model
generator = Generator()
generator.load_state_dict(torch.load('/content/drive/MyDrive/AI/Term 3/dataset/generator_epoch_2.pth'))
generator.eval()

def preprocess_image(image_path):
    transform = transforms.Compose([
        transforms.Resize((256, 256)),  # Resize the image to the required size
        transforms.ToTensor(),          # Convert image to tensor
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the image
    ])
    image = Image.open(image_path).convert('RGB')  # Open image and convert to RGB
    image = transform(image).unsqueeze(0)  # Add batch dimension
    return image


# Function to post-process and display images
def display_images(original, generated):
    # Denormalize and convert to numpy
    original = original.squeeze().numpy().transpose((1, 2, 0))  # Convert from [C, H, W] to [H, W, C]
    original = (original * 0.5) + 0.5  # Undo normalization

    generated = generated.squeeze().detach().numpy().transpose((1, 2, 0))  # Convert from [C, H, W] to [H, W, C]
    generated = (generated * 0.5) + 0.5  # Undo normalization

    fig, axes = plt.subplots(1, 2, figsize=(12, 6))
    axes[0].imshow(original)
    axes[0].set_title('Original Image')
    axes[0].axis('off')

    axes[1].imshow(generated)
    axes[1].set_title('Generated Image')
    axes[1].axis('off')

    plt.show()


# Path to the validation image
image_path = '/content/drive/MyDrive/AI/Term 3/dataset/val/low_res/0.png'

# Preprocess the image
input_image = preprocess_image(image_path)

# Generate the output image
with torch.no_grad():
    generated_image = generator(input_image)

# Display the original and generated images
display_images(input_image, generated_image)





